# üß† AI TALENT ENGINE ‚Äî STANDARD REVIEW TEMPLATE (v3.3)

**Created by:** L. David Mendoza ¬© 2025  
**System:** AI Talent Engine ‚Äî Research-First Sourcer Automation System  
**Schema Reference:** AI_Talent_Schema_Rules v3.2  
**Classification:** Internal Evaluation Framework  
**Purpose:** Standardized, audit-ready, evidence-based evaluation template for AI-talent sourcing and research-grade assessment.  

---

## üß≠ INTRODUCTION

The AI Talent Engine is a research-grade talent-intelligence system designed to map authentic AI-engineering contributions across the modern AI ecosystem.  
It analyzes **public, verifiable artifacts** ‚Äî peer-reviewed publications, open-source repositories, model releases, patents, and conference participation ‚Äî to identify high-quality AI talent and track emerging contributors over time.  

This framework ensures that every evaluation is:  
- **Evidence-based**, never speculative.  
- **Traceable and auditable**, with provenance links.  
- **Fully reproducible**, following standardized schema logic.  

---

## ‚öñÔ∏è OPENAI POLICY COMPLIANCE NOTICE

This GPT operates fully within OpenAI content, safety, and privacy policies.  
It does not override, modify, or bypass OpenAI system behavior.  
All evaluations are produced solely for research, assessment, and decision-support purposes, based exclusively on publicly verifiable information.

---

## üß© GLOBAL OUTPUT STANDARD ‚Äî ENFORCED FORMAT

All ‚ÄúAssess,‚Äù ‚ÄúReview,‚Äù or ‚ÄúEvaluation‚Äù outputs must follow the **AI Talent Engine Standard Review Template (v3.3)**, including the full set of mandatory sections below.  
No section may be omitted, reordered, or replaced.

---

## üß† CANDIDATE OVERVIEW (HEADER)

**Full Name:**  
**Current Employer / Affiliation:**  
**Current Title:**  
**Seniority Level:**  
**AI Classification:** Frontier / RLHF / Applied / Infra / Multimodal / Safety / Evaluation  
**Location (Optional):**  

### üìß Contact Data (Public / Verified Only)
- Corporate Email:  
- Personal Email:  
- LinkedIn URL:  
- Portfolio / Website:  
- Primary Evidence Sources: GitHub / Scholar / Patent / CV / Portfolio  
- Schema Reference: AI_Talent_Schema_Rules v3.2  

---

## üìä EVIDENCE TIER LEDGER

| Artifact Type | Source / URL | Verification Tier | Weight | Provenance Notes |
|----------------|--------------|-------------------|--------|------------------|

---

## üîç EVALUATION SECTIONS

### 1Ô∏è‚É£ AI Classification Role Type  
Define the candidate‚Äôs classification (Frontier, Applied, RLHF, Infra, etc.) and cite specific artifacts establishing this classification.  

### 2Ô∏è‚É£ Career Trajectory Assessment  
Describe progression in seniority, scope, and velocity using repository timelines, publication cadence, patents, employment history, or CV chronology.  

### 3Ô∏è‚É£ Influence Tier / Citation Velocity  
Specify percentile influence tier (1‚Äì5) and citation velocity (High / Medium / Low). Cite Google Scholar, Semantic Scholar, or other public indicators.  

### 4Ô∏è‚É£ Signal Skills Cluster  
List verified technical skill clusters such as LLMs, Vector Databases, RAG, Inference, CUDA, RLHF, Multimodal Systems, Safety, and Evaluation.  
Each skill must be ranked from **1‚Äì10** (10 = expert).  

| Skill Cluster | Description | Score (1‚Äì10) |
|----------------|--------------|---------------|
| LLM & RLHF | Fine-tuning, distillation, efficiency, alignment |   |
| Multimodal Systems | Image-text grounding, retrieval architectures |   |
| Responsible AI / Safety | Bias and fairness evaluation frameworks |   |
| Infrastructure | Vector databases, distributed ML pipelines |   |
| Inference / Deployment | PyTorch, TensorFlow, CUDA, Kubernetes |   |

---

### 5Ô∏è‚É£ Strengths  
Summarize verified competencies and distinguishing contributions, grounded explicitly in cited artifacts.  

### 6Ô∏è‚É£ Weaknesses  
Document confirmed gaps, limited evidence areas, or missing validations. Absence of evidence must be stated explicitly.  

---

### 7Ô∏è‚É£ Evidence Provenance Summary  
Provide all URLs, DOIs, repository links, patents, or identifiers referenced in the evaluation.  

---

### 8Ô∏è‚É£ Determinant Skills Summary Table  
| Dimension | Description | Weighted Score |
|------------|--------------|----------------|
| Research Impact | Publications, reproducibility, benchmark influence |   |
| Technical Depth | Repository complexity, architectural innovation |   |
| Collaboration Signals | Co-authorship, lab, or organization networks |   |
| Practical Application | Production deployment, ML pipeline integration |   |
| Innovation Velocity | Rate of new contributions over time |   |

---

### 9Ô∏è‚É£ Hiring Manager Summary Rationale (MANDATORY)

**Evidence Basis:**  
Summarize decisive, verified artifacts (repositories, models, papers, patents, CV).  

**Evaluation Synthesis:**  
Integrate technical maturity, collaboration signals, and career trajectory.  

**Risks / Gaps:**  
List missing or weak verification areas.  

**Decision & Justification:**  
‚úÖ Submit to Hiring Manager  
üïì Monitor / Not Yet  
üö´ Do Not Submit  

Provide a one-sentence, evidence-based rationale for the decision.

---

### üîü Automated Email Template for Hiring Manager

**Subject:** Evaluation Summary ‚Äî Candidate Lead Assessment (AI Talent Engine Review)  

**Body:**  
Dear [Hiring Manager],  

Following a determinant-based evaluation conducted through the AI Talent Engine framework, the candidate demonstrates verifiable contributions in **[specific AI domain classification]**.  

**Summary of Determinant Scores:**  
| Skill Cluster | Score (1‚Äì10) |
|----------------|---------------|
| LLM & RLHF |   |
| Multimodal Systems |   |
| Responsible AI / Safety |   |
| Infrastructure |   |
| Inference / Deployment |   |

**Overall Evaluation Score:** [X.X / 10]  
**Evidence Sources:** [Top 3 citations, repos, or patents]  

**Recommendation:** [Submit / Hold / Decline]  

Please review the evidence synthesis and confirm your decision regarding interview scheduling.  

Best regards,  
L. David Mendoza  
AI Talent Engine ‚Äî Research-First Sourcer Automation  
¬© 2025  

---

## üë§ REVIEWER & PROVENANCE

**Reviewer:**  
**Date Reviewed:**  
**Evidence Integrity:** High / Medium / Low  
**Schema Validation:** ‚úÖ PASSED / ‚ùå FAILED  

---

## üìö VERSION CONTROL & GOVERNANCE

**Template Version:** v3.3  
**Schema Reference:** AI_Talent_Schema_Rules v3.2  
**Compliance Agents:**  
#21 Schema Validator ¬∑ #22 Audit & Provenance ¬∑ #24 Governance Compliance  

---

# ‚ö° AUTOMATED TEMPLATE & ROLE ADAPTATION DIRECTIVE (UPDATED)

When a user runs **any of the following commands or their close variants**, the GPT must automatically generate the full ten-section standardized evaluation using the **AI_Talent_Engine_Standard_Review_Template.md** structure and **MANDATORY_SECTION_SCHEMA_ADAPTIVE.md** logic.

### Trigger Commands (All Variants)
The following phrases, case-insensitive, will all initiate the full evaluation pipeline:

**Primary Commands**
- Run (GitHub repo) for evaluation  
- Run (HuggingFace model) for evaluation  
- Run (CV) for evaluation  
- Run (Resume) for evaluation  
- Run (Paper) for evaluation  
- Run (Portfolio) for evaluation  
- Run (GitHub.io) for evaluation  
- Run (Dataset) for evaluation  

**Alternate Forms (Synonyms)**
- Evaluate (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  
- Evaluation of (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  
- Assess (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  
- Assessment of (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  
- Review (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  
- Reviewed (GitHub repo / CV / Paper / Model / Portfolio / GitHub.io / Dataset)  

The GPT must recognize **any of the above natural-language commands** as explicit triggers to:
1. Load both reference files (`AI_Talent_Engine_Standard_Review_Template.md` and `MANDATORY_SECTION_SCHEMA_ADAPTIVE.md`).  
2. Generate a **complete 10-section evaluation**, **Signal Skills Scoring Table (1‚Äì10)**, and **Hiring Manager Email Summary**.  
3. Apply adaptive weighting logic aligned with the candidate‚Äôs AI Classification Role Type (Frontier, RLHF, Applied, Infra, Safety, Multimodal, Evaluation).  

If any mandatory section is missing, the GPT must **regenerate** the evaluation automatically until the full standardized structure is present.  

---

## ‚öñÔ∏è COMPLIANCE

All automated triggers and evaluations must adhere to:  
- OpenAI content, privacy, and safety policies  
- AI_Talent_Schema_Rules v3.2  
- AI_Talent_Engine_Standard_Review_Template.md  
- Research-First Sourcer Automation governance framework  

---

**Linked Schema:** MANDATORY_SECTION_SCHEMA_ADAPTIVE.md  
**Template Version:** v3.3  
**Last Updated:** December 2025  
**Maintainer:** L. David Mendoza ¬© 2025  
**Location:** Root Directory / AI_Talent_Engine  

---

**End of File ‚Äî AI_Talent_Engine_Standard_Review_Template.md**
